{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{47, 39}\n"
     ]
    }
   ],
   "source": [
    "# from utils import process_csv\n",
    "# input_file = './dataset/20241106_testTX_constantUniform_simtime-100_num_nodes-50_BHradio-0_SFradio-0_fieldLength-20_uniform-1/MonitorSnifferRx.csv'\n",
    "# output_file = './dataset/20241106_testTX_constantUniform_simtime-100_num_nodes-50_BHradio-0_SFradio-0_fieldLength-20_uniform-1/ProcessedMonitorSnifferRx.csv'\n",
    "# log_file = './dataset/20241106_testTX_constantUniform_simtime-100_num_nodes-50_BHradio-0_SFradio-0_fieldLength-20_uniform-1/log1106_uniform_20#%20_seed_12345.txt'\n",
    "# process_csv(input_file, output_file, log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "import numpy as np\n",
    "import models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_file = 'D:/zhuomian/file/弱网中鲁棒性的恶意节点检测/exp/dataset/20241106_testTX_constantUniform_simtime-100_num_nodes-50_BHradio-0_SFradio-0_fieldLength-20_uniform-1/ProcessedMonitorSnifferRx.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(threshold=np.inf)  # 这将打印所有内容，去掉折叠\n",
    "processed_data, adj, T, group_num = load_data(1,data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 设置numpy的打印选项，显示更多行列\n",
    "\n",
    "\n",
    "# 打印节点特征（processed_data.x）\n",
    "# print(processed_data)\n",
    "# print(adj[12])\n",
    "# print(T[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印边连接关系（processed_data.edge_index）\n",
    "# print(processed_data[-1].edge_index.numpy().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 打印节点标签（processed_data.y）\n",
    "# print(processed_data[0].y.numpy())\n",
    "# print(processed_data[-1].x[:,0:8].numpy().size)\n",
    "# print(processed_data[0].y.numpy())\n",
    "# print(processed_data[12].edge_index)\n",
    "# print(processed_data[12].edge_weights)\n",
    "# print(processed_data[12].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HypergraphModel(\n",
      "  (layer1): HypergraphConvLayer(\n",
      "    (conv): HypergraphConv(8, 32)\n",
      "  )\n",
      "  (edge_conv): GraphConvolution()\n",
      "  (class_classifier): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      "  (norm1): CustomBatchNorm()\n",
      "  (norm2): CustomBatchNorm()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_model = models.HypergraphModel(8, 3)\n",
    "print(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "from utils import accuracy, auc, precision, recall, f1_score\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "weight_decay = 5e-4\n",
    "optimizer = optim.Adam(train_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "acc_measure = accuracy\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    train_model.train()\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    # print(processed_data[0].x[0:8].shape)\n",
    "    # print(processed_data[0].edge_weights.shape)\n",
    "    # print(processed_data[0].edge_index.shape)\n",
    "    for i in range(group_num):\n",
    "        print(i)\n",
    "        output = train_model(processed_data[i].x[:, 0:8], processed_data[i].edge_index, \n",
    "                                 processed_data[i].edge_weights, processed_data[i].x[:, 8:11], adj[i], T[i])\n",
    "        # print(output)\n",
    "        labels = processed_data[i].y\n",
    "        loss_train = criteria(output, labels)\n",
    "        # print(output[:, 1])\n",
    "        acc_train = acc_measure(output, labels)\n",
    "        \n",
    "        loss_train.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_model.eval()\n",
    "        output = train_model(processed_data[i].x[:, 0:8], processed_data[i].edge_index, \n",
    "                                 processed_data[i].edge_weights, processed_data[i].x[:, 8:11], adj[i], T[i])\n",
    "        # print(output)\n",
    "        loss_val = criteria(output, labels)\n",
    "        acc_val = acc_measure(output, labels)\n",
    "        auc_val = auc(output, labels)\n",
    "        per_val = precision(output, labels)\n",
    "        recall_val = recall(output, labels)\n",
    "        f1_val = f1_score(output, labels)\n",
    "        print(\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "            'auc_val: {:.4f}'.format(auc_val),\n",
    "            'per_val: {:.4f}'.format(per_val),\n",
    "            'recall_val: {:.4f}'.format(recall_val),\n",
    "            'f1_val: {:.4f}'.format(f1_val),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    train_model.eval()\n",
    "    output = train_model(processed_data[group_num-1].x[:, 0:8], processed_data[group_num-1].edge_index, \n",
    "                             processed_data[group_num-1].edge_weights, processed_data[group_num-1].x[:, 8:11], adj[group_num-1], T[group_num-1])\n",
    "    labels = processed_data[group_num-1].y\n",
    "    \n",
    "    loss_test = criteria(output, labels)\n",
    "    acc_test = acc_measure(output, labels)\n",
    "    auc_test = auc(output, labels)\n",
    "    per_test = precision(output, labels)\n",
    "    recall_test = recall(output, labels)\n",
    "    f1_test = f1_score(output, labels)\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()),\n",
    "         'auc_test: {:.4f}'.format(auc_test),\n",
    "            'per_test: {:.4f}'.format(per_test),\n",
    "            'recall_test: {:.4f}'.format(recall_test),\n",
    "            'f1_test: {:.4f}'.format(f1_test))\n",
    "    return acc_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss_train: 0.6182 acc_train: 0.9000 loss_val: 0.3239 acc_val: 0.9000 auc_val: 0.6578 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0245s\n",
      "1\n",
      "loss_train: 0.3471 acc_train: 0.9000 loss_val: 0.3757 acc_val: 0.9000 auc_val: 0.6311 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0479s\n",
      "2\n",
      "loss_train: 0.4213 acc_train: 0.9000 loss_val: 0.3314 acc_val: 0.9000 auc_val: 0.7778 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0684s\n",
      "3\n",
      "loss_train: 0.3633 acc_train: 0.9000 loss_val: 0.3561 acc_val: 0.9000 auc_val: 0.5022 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0845s\n",
      "4\n",
      "loss_train: 0.3292 acc_train: 0.9000 loss_val: 0.3391 acc_val: 0.9000 auc_val: 0.6133 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1005s\n",
      "5\n",
      "loss_train: 0.4033 acc_train: 0.9000 loss_val: 0.4958 acc_val: 0.9000 auc_val: 0.4000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1148s\n",
      "6\n",
      "loss_train: 0.4144 acc_train: 0.9000 loss_val: 0.5001 acc_val: 0.9000 auc_val: 0.6756 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1310s\n",
      "7\n",
      "loss_train: 0.6632 acc_train: 0.9000 loss_val: 0.7351 acc_val: 0.9000 auc_val: 0.4667 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1471s\n",
      "8\n",
      "loss_train: 0.7772 acc_train: 0.9000 loss_val: 0.7985 acc_val: 0.9000 auc_val: 0.5956 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1611s\n",
      "9\n",
      "loss_train: 0.6291 acc_train: 0.9000 loss_val: 0.6080 acc_val: 0.9000 auc_val: 0.7867 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1745s\n",
      "10\n",
      "loss_train: 0.7083 acc_train: 0.9000 loss_val: 0.6566 acc_val: 0.9000 auc_val: 0.5911 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1897s\n",
      "11\n",
      "loss_train: 0.5581 acc_train: 0.9000 loss_val: 0.5012 acc_val: 0.9000 auc_val: 0.7111 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2039s\n",
      "12\n",
      "loss_train: 0.6420 acc_train: 0.6000 loss_val: 0.6414 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2099s\n",
      "13\n",
      "loss_train: 0.5368 acc_train: 1.0000 loss_val: 0.5338 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2149s\n",
      "14\n",
      "loss_train: 0.5336 acc_train: 1.0000 loss_val: 0.5298 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2204s\n",
      "15\n",
      "loss_train: 0.5300 acc_train: 1.0000 loss_val: 0.5258 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2267s\n",
      "16\n",
      "loss_train: 0.5254 acc_train: 1.0000 loss_val: 0.5202 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2321s\n",
      "17\n",
      "loss_train: 0.5207 acc_train: 1.0000 loss_val: 0.5150 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2371s\n",
      "18\n",
      "loss_train: 0.5148 acc_train: 1.0000 loss_val: 0.5089 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2421s\n",
      "19\n",
      "loss_train: 0.5089 acc_train: 1.0000 loss_val: 0.5030 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2472s\n",
      "20\n",
      "loss_train: 0.5031 acc_train: 1.0000 loss_val: 0.4970 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2512s\n",
      "21\n",
      "loss_train: 0.4970 acc_train: 1.0000 loss_val: 0.4911 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2564s\n",
      "22\n",
      "loss_train: 0.4908 acc_train: 1.0000 loss_val: 0.4850 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2614s\n",
      "23\n",
      "loss_train: 0.4854 acc_train: 1.0000 loss_val: 0.4803 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2660s\n",
      "24\n",
      "loss_train: 0.4798 acc_train: 1.0000 loss_val: 0.4741 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2700s\n",
      "25\n",
      "loss_train: 0.4744 acc_train: 1.0000 loss_val: 0.4657 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2740s\n",
      "26\n",
      "loss_train: 0.4655 acc_train: 1.0000 loss_val: 0.4567 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2800s\n",
      "27\n",
      "loss_train: 0.4569 acc_train: 1.0000 loss_val: 0.4478 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2850s\n",
      "28\n",
      "loss_train: 0.4474 acc_train: 1.0000 loss_val: 0.4384 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2890s\n",
      "29\n",
      "loss_train: 0.4388 acc_train: 1.0000 loss_val: 0.4291 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2941s\n",
      "30\n",
      "loss_train: 0.4287 acc_train: 1.0000 loss_val: 0.4183 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2981s\n",
      "31\n",
      "loss_train: 0.4188 acc_train: 1.0000 loss_val: 0.4082 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3021s\n",
      "32\n",
      "loss_train: 0.4076 acc_train: 1.0000 loss_val: 0.3966 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3073s\n",
      "33\n",
      "loss_train: 0.3971 acc_train: 1.0000 loss_val: 0.3847 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3121s\n",
      "34\n",
      "loss_train: 0.3842 acc_train: 1.0000 loss_val: 0.3705 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3171s\n",
      "35\n",
      "loss_train: 0.3712 acc_train: 1.0000 loss_val: 0.3565 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3216s\n",
      "36\n",
      "loss_train: 0.5270 acc_train: 0.9000 loss_val: 0.5387 acc_val: 0.9000 auc_val: 0.4889 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3360s\n",
      "37\n",
      "loss_train: 0.8177 acc_train: 0.9000 loss_val: 0.7988 acc_val: 0.9000 auc_val: 0.6756 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3514s\n",
      "38\n",
      "loss_train: 0.7391 acc_train: 0.9000 loss_val: 0.6701 acc_val: 0.9000 auc_val: 0.7200 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3660s\n",
      "Test set results: loss= 0.6701 accuracy= 0.9000 auc_test: 0.7200 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.4677 acc_train: 0.9000 loss_val: 0.3191 acc_val: 0.9000 auc_val: 0.6133 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0183s\n",
      "1\n",
      "loss_train: 0.3679 acc_train: 0.9000 loss_val: 0.3715 acc_val: 0.9000 auc_val: 0.3289 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0342s\n",
      "2\n",
      "loss_train: 0.2921 acc_train: 0.9000 loss_val: 0.3009 acc_val: 0.9000 auc_val: 0.8222 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0478s\n",
      "3\n",
      "loss_train: 0.3850 acc_train: 0.9000 loss_val: 0.3859 acc_val: 0.9000 auc_val: 0.4400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0636s\n",
      "4\n",
      "loss_train: 0.4039 acc_train: 0.9000 loss_val: 0.3999 acc_val: 0.9000 auc_val: 0.5422 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0799s\n",
      "5\n",
      "loss_train: 0.3919 acc_train: 0.9000 loss_val: 0.3831 acc_val: 0.9000 auc_val: 0.5333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0968s\n",
      "6\n",
      "loss_train: 0.3438 acc_train: 0.9000 loss_val: 0.3312 acc_val: 0.9000 auc_val: 0.6178 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1135s\n",
      "7\n",
      "loss_train: 0.3646 acc_train: 0.9000 loss_val: 0.3618 acc_val: 0.9000 auc_val: 0.4089 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1302s\n",
      "8\n",
      "loss_train: 0.3622 acc_train: 0.9000 loss_val: 0.3696 acc_val: 0.9000 auc_val: 0.3822 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1479s\n",
      "9\n",
      "loss_train: 0.3055 acc_train: 0.9000 loss_val: 0.3083 acc_val: 0.9000 auc_val: 0.6622 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1655s\n",
      "10\n",
      "loss_train: 0.3398 acc_train: 0.9000 loss_val: 0.3560 acc_val: 0.9000 auc_val: 0.5911 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1825s\n",
      "11\n",
      "loss_train: 0.3018 acc_train: 0.9000 loss_val: 0.3204 acc_val: 0.9000 auc_val: 0.7867 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1995s\n",
      "12\n",
      "loss_train: 0.6627 acc_train: 0.6000 loss_val: 0.6630 acc_val: 0.6000 auc_val: 0.7500 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2073s\n",
      "13\n",
      "loss_train: 0.3059 acc_train: 1.0000 loss_val: 0.3022 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2134s\n",
      "14\n",
      "loss_train: 0.3016 acc_train: 1.0000 loss_val: 0.2972 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2184s\n",
      "15\n",
      "loss_train: 0.2977 acc_train: 1.0000 loss_val: 0.2925 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2248s\n",
      "16\n",
      "loss_train: 0.2918 acc_train: 1.0000 loss_val: 0.2856 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2299s\n",
      "17\n",
      "loss_train: 0.2868 acc_train: 1.0000 loss_val: 0.2797 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2354s\n",
      "18\n",
      "loss_train: 0.2786 acc_train: 1.0000 loss_val: 0.2705 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2414s\n",
      "19\n",
      "loss_train: 0.2710 acc_train: 1.0000 loss_val: 0.2619 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2463s\n",
      "20\n",
      "loss_train: 0.2623 acc_train: 1.0000 loss_val: 0.2523 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2519s\n",
      "21\n",
      "loss_train: 0.2518 acc_train: 1.0000 loss_val: 0.2408 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2571s\n",
      "22\n",
      "loss_train: 0.2405 acc_train: 1.0000 loss_val: 0.2287 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2615s\n",
      "23\n",
      "loss_train: 0.2300 acc_train: 1.0000 loss_val: 0.2175 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2675s\n",
      "24\n",
      "loss_train: 0.2160 acc_train: 1.0000 loss_val: 0.2027 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2728s\n",
      "25\n",
      "loss_train: 0.2029 acc_train: 1.0000 loss_val: 0.1885 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2788s\n",
      "26\n",
      "loss_train: 0.1900 acc_train: 1.0000 loss_val: 0.1754 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2858s\n",
      "27\n",
      "loss_train: 0.1737 acc_train: 1.0000 loss_val: 0.1585 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2909s\n",
      "28\n",
      "loss_train: 0.1588 acc_train: 1.0000 loss_val: 0.1435 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2968s\n",
      "29\n",
      "loss_train: 0.1431 acc_train: 1.0000 loss_val: 0.1277 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3018s\n",
      "30\n",
      "loss_train: 0.1282 acc_train: 1.0000 loss_val: 0.1131 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3072s\n",
      "31\n",
      "loss_train: 0.1125 acc_train: 1.0000 loss_val: 0.0976 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3112s\n",
      "32\n",
      "loss_train: 0.0998 acc_train: 1.0000 loss_val: 0.0855 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3165s\n",
      "33\n",
      "loss_train: 0.0834 acc_train: 1.0000 loss_val: 0.0700 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3213s\n",
      "34\n",
      "loss_train: 0.0707 acc_train: 1.0000 loss_val: 0.0582 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3269s\n",
      "35\n",
      "loss_train: 0.0575 acc_train: 1.0000 loss_val: 0.0463 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3322s\n",
      "36\n",
      "loss_train: 1.7421 acc_train: 0.9000 loss_val: 1.7810 acc_val: 0.9000 auc_val: 0.5644 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3489s\n",
      "37\n",
      "loss_train: 3.0519 acc_train: 0.9000 loss_val: 3.0656 acc_val: 0.9000 auc_val: 0.7022 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3651s\n",
      "38\n",
      "loss_train: 2.8552 acc_train: 0.9000 loss_val: 2.7964 acc_val: 0.9000 auc_val: 0.7289 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3821s\n",
      "Test set results: loss= 2.7964 accuracy= 0.9000 auc_test: 0.7289 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3396 acc_train: 0.9000 loss_val: 0.8142 acc_val: 0.9000 auc_val: 0.6178 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0180s\n",
      "1\n",
      "loss_train: 1.3879 acc_train: 0.9000 loss_val: 1.3683 acc_val: 0.9000 auc_val: 0.4667 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0365s\n",
      "2\n",
      "loss_train: 0.7008 acc_train: 0.9000 loss_val: 0.6895 acc_val: 0.9000 auc_val: 0.7467 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0536s\n",
      "3\n",
      "loss_train: 1.2534 acc_train: 0.9000 loss_val: 1.2191 acc_val: 0.9000 auc_val: 0.4800 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0733s\n",
      "4\n",
      "loss_train: 0.7481 acc_train: 0.9000 loss_val: 0.7222 acc_val: 0.9000 auc_val: 0.6444 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0901s\n",
      "5\n",
      "loss_train: 0.9292 acc_train: 0.9000 loss_val: 0.8923 acc_val: 0.9000 auc_val: 0.4400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1063s\n",
      "6\n",
      "loss_train: 0.6983 acc_train: 0.9000 loss_val: 0.6644 acc_val: 0.9000 auc_val: 0.6800 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1242s\n",
      "7\n",
      "loss_train: 0.9432 acc_train: 0.9000 loss_val: 0.8876 acc_val: 0.9000 auc_val: 0.5111 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1406s\n",
      "8\n",
      "loss_train: 0.9483 acc_train: 0.9000 loss_val: 0.8814 acc_val: 0.9000 auc_val: 0.5689 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1576s\n",
      "9\n",
      "loss_train: 0.6543 acc_train: 0.9000 loss_val: 0.6035 acc_val: 0.9000 auc_val: 0.8133 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1769s\n",
      "10\n",
      "loss_train: 0.7267 acc_train: 0.9000 loss_val: 0.6664 acc_val: 0.9000 auc_val: 0.6267 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1925s\n",
      "11\n",
      "loss_train: 0.5354 acc_train: 0.9000 loss_val: 0.4887 acc_val: 0.9000 auc_val: 0.7733 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2102s\n",
      "12\n",
      "loss_train: 0.6734 acc_train: 0.6000 loss_val: 0.6893 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2189s\n",
      "13\n",
      "loss_train: 0.0015 acc_train: 1.0000 loss_val: 0.0013 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2254s\n",
      "14\n",
      "loss_train: 0.0014 acc_train: 1.0000 loss_val: 0.0012 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2304s\n",
      "15\n",
      "loss_train: 0.0011 acc_train: 1.0000 loss_val: 0.0010 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2361s\n",
      "16\n",
      "loss_train: 0.0010 acc_train: 1.0000 loss_val: 0.0009 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2412s\n",
      "17\n",
      "loss_train: 0.0010 acc_train: 1.0000 loss_val: 0.0009 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2463s\n",
      "18\n",
      "loss_train: 0.0008 acc_train: 1.0000 loss_val: 0.0007 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2524s\n",
      "19\n",
      "loss_train: 0.0007 acc_train: 1.0000 loss_val: 0.0006 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2583s\n",
      "20\n",
      "loss_train: 0.0007 acc_train: 1.0000 loss_val: 0.0006 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2628s\n",
      "21\n",
      "loss_train: 0.0005 acc_train: 1.0000 loss_val: 0.0005 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2688s\n",
      "22\n",
      "loss_train: 0.0005 acc_train: 1.0000 loss_val: 0.0004 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2739s\n",
      "23\n",
      "loss_train: 0.0005 acc_train: 1.0000 loss_val: 0.0004 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2789s\n",
      "24\n",
      "loss_train: 0.0004 acc_train: 1.0000 loss_val: 0.0004 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2849s\n",
      "25\n",
      "loss_train: 0.0003 acc_train: 1.0000 loss_val: 0.0003 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2909s\n",
      "26\n",
      "loss_train: 0.0004 acc_train: 1.0000 loss_val: 0.0003 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2959s\n",
      "27\n",
      "loss_train: 0.0003 acc_train: 1.0000 loss_val: 0.0003 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3019s\n",
      "28\n",
      "loss_train: 0.0003 acc_train: 1.0000 loss_val: 0.0002 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3079s\n",
      "29\n",
      "loss_train: 0.0002 acc_train: 1.0000 loss_val: 0.0002 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3129s\n",
      "30\n",
      "loss_train: 0.0002 acc_train: 1.0000 loss_val: 0.0002 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3195s\n",
      "31\n",
      "loss_train: 0.0002 acc_train: 1.0000 loss_val: 0.0002 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3263s\n",
      "32\n",
      "loss_train: 0.0002 acc_train: 1.0000 loss_val: 0.0002 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3323s\n",
      "33\n",
      "loss_train: 0.0002 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3378s\n",
      "34\n",
      "loss_train: 0.0002 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3435s\n",
      "35\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3490s\n",
      "36\n",
      "loss_train: 0.5196 acc_train: 0.9000 loss_val: 0.4969 acc_val: 0.9000 auc_val: 0.4044 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3683s\n",
      "37\n",
      "loss_train: 0.5503 acc_train: 0.9000 loss_val: 0.4925 acc_val: 0.9000 auc_val: 0.4978 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3865s\n",
      "38\n",
      "loss_train: 0.5163 acc_train: 0.9000 loss_val: 0.4168 acc_val: 0.9000 auc_val: 0.4844 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4056s\n",
      "Test set results: loss= 0.4168 accuracy= 0.9000 auc_test: 0.4844 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3290 acc_train: 0.9000 loss_val: 0.4385 acc_val: 0.9000 auc_val: 0.5067 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0186s\n",
      "1\n",
      "loss_train: 0.4186 acc_train: 0.9000 loss_val: 0.4511 acc_val: 0.9000 auc_val: 0.4889 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0364s\n",
      "2\n",
      "loss_train: 0.3830 acc_train: 0.9000 loss_val: 0.3972 acc_val: 0.9000 auc_val: 0.6800 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0531s\n",
      "3\n",
      "loss_train: 0.5529 acc_train: 0.9000 loss_val: 0.5794 acc_val: 0.9000 auc_val: 0.4356 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0674s\n",
      "4\n",
      "loss_train: 0.5372 acc_train: 0.9000 loss_val: 0.5484 acc_val: 0.9000 auc_val: 0.4000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0859s\n",
      "5\n",
      "loss_train: 0.5439 acc_train: 0.9000 loss_val: 0.5497 acc_val: 0.9000 auc_val: 0.3733 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1012s\n",
      "6\n",
      "loss_train: 0.4703 acc_train: 0.9000 loss_val: 0.4691 acc_val: 0.9000 auc_val: 0.5867 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1158s\n",
      "7\n",
      "loss_train: 0.5433 acc_train: 0.9000 loss_val: 0.5382 acc_val: 0.9000 auc_val: 0.3867 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1318s\n",
      "8\n",
      "loss_train: 0.6170 acc_train: 0.9000 loss_val: 0.6062 acc_val: 0.9000 auc_val: 0.2622 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1496s\n",
      "9\n",
      "loss_train: 0.5552 acc_train: 0.9000 loss_val: 0.5396 acc_val: 0.9000 auc_val: 0.4178 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1639s\n",
      "10\n",
      "loss_train: 0.5546 acc_train: 0.9000 loss_val: 0.5354 acc_val: 0.9000 auc_val: 0.4044 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1779s\n",
      "11\n",
      "loss_train: 0.4719 acc_train: 0.9000 loss_val: 0.4531 acc_val: 0.9000 auc_val: 0.4622 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1919s\n",
      "12\n",
      "loss_train: 1.2507 acc_train: 0.6000 loss_val: 1.2279 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1986s\n",
      "13\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0002 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2036s\n",
      "14\n",
      "loss_train: 0.0002 acc_train: 1.0000 loss_val: 0.0003 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2096s\n",
      "15\n",
      "loss_train: 0.0003 acc_train: 1.0000 loss_val: 0.0003 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2168s\n",
      "16\n",
      "loss_train: 0.0004 acc_train: 1.0000 loss_val: 0.0005 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2235s\n",
      "17\n",
      "loss_train: 0.0006 acc_train: 1.0000 loss_val: 0.0008 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2301s\n",
      "18\n",
      "loss_train: 0.0007 acc_train: 1.0000 loss_val: 0.0009 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2359s\n",
      "19\n",
      "loss_train: 0.0009 acc_train: 1.0000 loss_val: 0.0012 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2420s\n",
      "20\n",
      "loss_train: 0.0015 acc_train: 1.0000 loss_val: 0.0019 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2477s\n",
      "21\n",
      "loss_train: 0.0016 acc_train: 1.0000 loss_val: 0.0021 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2544s\n",
      "22\n",
      "loss_train: 0.0022 acc_train: 1.0000 loss_val: 0.0028 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2599s\n",
      "23\n",
      "loss_train: 0.0030 acc_train: 1.0000 loss_val: 0.0038 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2659s\n",
      "24\n",
      "loss_train: 0.0036 acc_train: 1.0000 loss_val: 0.0045 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2716s\n",
      "25\n",
      "loss_train: 0.0044 acc_train: 1.0000 loss_val: 0.0055 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2780s\n",
      "26\n",
      "loss_train: 0.0061 acc_train: 1.0000 loss_val: 0.0075 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2835s\n",
      "27\n",
      "loss_train: 0.0069 acc_train: 1.0000 loss_val: 0.0084 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2894s\n",
      "28\n",
      "loss_train: 0.0086 acc_train: 1.0000 loss_val: 0.0105 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2954s\n",
      "29\n",
      "loss_train: 0.0103 acc_train: 1.0000 loss_val: 0.0125 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3014s\n",
      "30\n",
      "loss_train: 0.0126 acc_train: 1.0000 loss_val: 0.0151 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3071s\n",
      "31\n",
      "loss_train: 0.0149 acc_train: 1.0000 loss_val: 0.0177 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3131s\n",
      "32\n",
      "loss_train: 0.0188 acc_train: 1.0000 loss_val: 0.0219 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3176s\n",
      "33\n",
      "loss_train: 0.0208 acc_train: 1.0000 loss_val: 0.0242 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3226s\n",
      "34\n",
      "loss_train: 0.0244 acc_train: 1.0000 loss_val: 0.0280 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3266s\n",
      "35\n",
      "loss_train: 0.0278 acc_train: 1.0000 loss_val: 0.0316 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3316s\n",
      "36\n",
      "loss_train: 0.4719 acc_train: 0.9000 loss_val: 0.4570 acc_val: 0.9000 auc_val: 0.6844 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3473s\n",
      "37\n",
      "loss_train: 0.4877 acc_train: 0.9000 loss_val: 0.4525 acc_val: 0.9000 auc_val: 0.5511 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3648s\n",
      "38\n",
      "loss_train: 0.5196 acc_train: 0.9000 loss_val: 0.4790 acc_val: 0.9000 auc_val: 0.6800 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3798s\n",
      "Test set results: loss= 0.4790 accuracy= 0.9000 auc_test: 0.6800 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3985 acc_train: 0.9000 loss_val: 0.4796 acc_val: 0.9000 auc_val: 0.5111 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0170s\n",
      "1\n",
      "loss_train: 0.4006 acc_train: 0.9000 loss_val: 0.3938 acc_val: 0.9000 auc_val: 0.6444 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0346s\n",
      "2\n",
      "loss_train: 0.4185 acc_train: 0.9000 loss_val: 0.4110 acc_val: 0.9000 auc_val: 0.6844 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0517s\n",
      "3\n",
      "loss_train: 0.4107 acc_train: 0.9000 loss_val: 0.4058 acc_val: 0.9000 auc_val: 0.6178 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0688s\n",
      "4\n",
      "loss_train: 0.4014 acc_train: 0.9000 loss_val: 0.3957 acc_val: 0.9000 auc_val: 0.8000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0868s\n",
      "5\n",
      "loss_train: 0.4376 acc_train: 0.9000 loss_val: 0.4342 acc_val: 0.9000 auc_val: 0.5556 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1038s\n",
      "6\n",
      "loss_train: 0.3947 acc_train: 0.9000 loss_val: 0.3891 acc_val: 0.9000 auc_val: 0.6533 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1239s\n",
      "7\n",
      "loss_train: 0.3874 acc_train: 0.9000 loss_val: 0.3827 acc_val: 0.9000 auc_val: 0.5733 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1443s\n",
      "8\n",
      "loss_train: 0.3333 acc_train: 0.9000 loss_val: 0.3274 acc_val: 0.9000 auc_val: 0.7511 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1635s\n",
      "9\n",
      "loss_train: 0.3188 acc_train: 0.9000 loss_val: 0.3117 acc_val: 0.9000 auc_val: 0.8444 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1813s\n",
      "10\n",
      "loss_train: 0.3540 acc_train: 0.9000 loss_val: 0.3490 acc_val: 0.9000 auc_val: 0.6622 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1993s\n",
      "11\n",
      "loss_train: 0.3384 acc_train: 0.9000 loss_val: 0.3321 acc_val: 0.9000 auc_val: 0.7733 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2188s\n",
      "12\n",
      "loss_train: 0.6390 acc_train: 0.6000 loss_val: 0.6390 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2264s\n",
      "13\n",
      "loss_train: 0.0534 acc_train: 1.0000 loss_val: 0.0536 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2328s\n",
      "14\n",
      "loss_train: 0.0535 acc_train: 1.0000 loss_val: 0.0535 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2380s\n",
      "15\n",
      "loss_train: 0.0535 acc_train: 1.0000 loss_val: 0.0531 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2455s\n",
      "16\n",
      "loss_train: 0.0534 acc_train: 1.0000 loss_val: 0.0526 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2510s\n",
      "17\n",
      "loss_train: 0.0533 acc_train: 1.0000 loss_val: 0.0521 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2574s\n",
      "18\n",
      "loss_train: 0.0511 acc_train: 1.0000 loss_val: 0.0496 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2634s\n",
      "19\n",
      "loss_train: 0.0496 acc_train: 1.0000 loss_val: 0.0476 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2694s\n",
      "20\n",
      "loss_train: 0.0485 acc_train: 1.0000 loss_val: 0.0462 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2744s\n",
      "21\n",
      "loss_train: 0.0453 acc_train: 1.0000 loss_val: 0.0426 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2794s\n",
      "22\n",
      "loss_train: 0.0426 acc_train: 1.0000 loss_val: 0.0397 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2858s\n",
      "23\n",
      "loss_train: 0.0405 acc_train: 1.0000 loss_val: 0.0373 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2908s\n",
      "24\n",
      "loss_train: 0.0365 acc_train: 1.0000 loss_val: 0.0332 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2948s\n",
      "25\n",
      "loss_train: 0.0332 acc_train: 1.0000 loss_val: 0.0298 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2998s\n",
      "26\n",
      "loss_train: 0.0305 acc_train: 1.0000 loss_val: 0.0271 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3058s\n",
      "27\n",
      "loss_train: 0.0264 acc_train: 1.0000 loss_val: 0.0231 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3108s\n",
      "28\n",
      "loss_train: 0.0232 acc_train: 1.0000 loss_val: 0.0201 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3159s\n",
      "29\n",
      "loss_train: 0.0200 acc_train: 1.0000 loss_val: 0.0171 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3204s\n",
      "30\n",
      "loss_train: 0.0172 acc_train: 1.0000 loss_val: 0.0145 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3259s\n",
      "31\n",
      "loss_train: 0.0145 acc_train: 1.0000 loss_val: 0.0121 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3309s\n",
      "32\n",
      "loss_train: 0.0125 acc_train: 1.0000 loss_val: 0.0103 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3358s\n",
      "33\n",
      "loss_train: 0.0099 acc_train: 1.0000 loss_val: 0.0080 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3409s\n",
      "34\n",
      "loss_train: 0.0081 acc_train: 1.0000 loss_val: 0.0065 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3459s\n",
      "35\n",
      "loss_train: 0.0064 acc_train: 1.0000 loss_val: 0.0050 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3515s\n",
      "36\n",
      "loss_train: 0.4298 acc_train: 0.9000 loss_val: 0.4408 acc_val: 0.9000 auc_val: 0.5956 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3701s\n",
      "37\n",
      "loss_train: 0.8264 acc_train: 0.9000 loss_val: 0.8578 acc_val: 0.9000 auc_val: 0.6844 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3878s\n",
      "38\n",
      "loss_train: 0.7743 acc_train: 0.9000 loss_val: 0.7967 acc_val: 0.9000 auc_val: 0.7022 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4047s\n",
      "Test set results: loss= 0.7967 accuracy= 0.9000 auc_test: 0.7022 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3706 acc_train: 0.9000 loss_val: 0.3422 acc_val: 0.9000 auc_val: 0.5911 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0145s\n",
      "1\n",
      "loss_train: 0.4676 acc_train: 0.9000 loss_val: 0.4756 acc_val: 0.9000 auc_val: 0.5289 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0305s\n",
      "2\n",
      "loss_train: 0.3306 acc_train: 0.9000 loss_val: 0.3333 acc_val: 0.9000 auc_val: 0.7244 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0494s\n",
      "3\n",
      "loss_train: 0.4323 acc_train: 0.9000 loss_val: 0.4353 acc_val: 0.9000 auc_val: 0.5600 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0661s\n",
      "4\n",
      "loss_train: 0.2909 acc_train: 0.9000 loss_val: 0.2911 acc_val: 0.9000 auc_val: 0.7556 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0820s\n",
      "5\n",
      "loss_train: 0.4272 acc_train: 0.9000 loss_val: 0.4284 acc_val: 0.9000 auc_val: 0.5067 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0977s\n",
      "6\n",
      "loss_train: 0.3233 acc_train: 0.9000 loss_val: 0.3226 acc_val: 0.9000 auc_val: 0.6978 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1117s\n",
      "7\n",
      "loss_train: 0.4355 acc_train: 0.9000 loss_val: 0.4348 acc_val: 0.9000 auc_val: 0.5556 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1282s\n",
      "8\n",
      "loss_train: 0.3428 acc_train: 0.9000 loss_val: 0.3405 acc_val: 0.9000 auc_val: 0.7244 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1442s\n",
      "9\n",
      "loss_train: 0.2468 acc_train: 0.9000 loss_val: 0.2443 acc_val: 0.9000 auc_val: 0.8756 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1592s\n",
      "10\n",
      "loss_train: 0.3619 acc_train: 0.9000 loss_val: 0.3591 acc_val: 0.9000 auc_val: 0.6800 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1744s\n",
      "11\n",
      "loss_train: 0.2899 acc_train: 0.9000 loss_val: 0.2873 acc_val: 0.9000 auc_val: 0.7867 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1924s\n",
      "12\n",
      "loss_train: 1.1621 acc_train: 0.6000 loss_val: 1.1675 acc_val: 0.6000 auc_val: 0.7500 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2014s\n",
      "13\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2094s\n",
      "14\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2170s\n",
      "15\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2240s\n",
      "16\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2315s\n",
      "17\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2385s\n",
      "18\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2456s\n",
      "19\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2529s\n",
      "20\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2600s\n",
      "21\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2673s\n",
      "22\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2744s\n",
      "23\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2821s\n",
      "24\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2889s\n",
      "25\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2966s\n",
      "26\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3039s\n",
      "27\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3106s\n",
      "28\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3181s\n",
      "29\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3251s\n",
      "30\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3318s\n",
      "31\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3391s\n",
      "32\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3456s\n",
      "33\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3506s\n",
      "34\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3563s\n",
      "35\n",
      "loss_train: 0.0001 acc_train: 1.0000 loss_val: 0.0001 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3630s\n",
      "36\n",
      "loss_train: 0.4606 acc_train: 0.9000 loss_val: 0.4709 acc_val: 0.9000 auc_val: 0.7022 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3813s\n",
      "37\n",
      "loss_train: 0.4106 acc_train: 0.9000 loss_val: 0.4205 acc_val: 0.9000 auc_val: 0.5822 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4015s\n",
      "38\n",
      "loss_train: 0.4669 acc_train: 0.9000 loss_val: 0.4625 acc_val: 0.9000 auc_val: 0.5644 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4196s\n",
      "Test set results: loss= 0.4625 accuracy= 0.9000 auc_test: 0.5644 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3661 acc_train: 0.9000 loss_val: 0.5030 acc_val: 0.9000 auc_val: 0.4533 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0170s\n",
      "1\n",
      "loss_train: 0.4152 acc_train: 0.9000 loss_val: 0.4178 acc_val: 0.9000 auc_val: 0.6489 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0330s\n",
      "2\n",
      "loss_train: 0.4423 acc_train: 0.9000 loss_val: 0.4429 acc_val: 0.9000 auc_val: 0.6133 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0507s\n",
      "3\n",
      "loss_train: 0.4337 acc_train: 0.9000 loss_val: 0.4334 acc_val: 0.9000 auc_val: 0.7822 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0692s\n",
      "4\n",
      "loss_train: 0.4280 acc_train: 0.9000 loss_val: 0.4265 acc_val: 0.9000 auc_val: 0.8444 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0864s\n",
      "5\n",
      "loss_train: 0.4528 acc_train: 0.9000 loss_val: 0.4507 acc_val: 0.9000 auc_val: 0.6178 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1044s\n",
      "6\n",
      "loss_train: 0.4335 acc_train: 0.9000 loss_val: 0.4300 acc_val: 0.9000 auc_val: 0.7600 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1184s\n",
      "7\n",
      "loss_train: 0.4288 acc_train: 0.9000 loss_val: 0.4245 acc_val: 0.9000 auc_val: 0.6089 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1369s\n",
      "8\n",
      "loss_train: 0.3920 acc_train: 0.9000 loss_val: 0.3857 acc_val: 0.9000 auc_val: 0.8400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1514s\n",
      "9\n",
      "loss_train: 0.3719 acc_train: 0.9000 loss_val: 0.3647 acc_val: 0.9000 auc_val: 0.9289 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1662s\n",
      "10\n",
      "loss_train: 0.3887 acc_train: 0.9000 loss_val: 0.3827 acc_val: 0.9000 auc_val: 0.7689 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1818s\n",
      "11\n",
      "loss_train: 0.3888 acc_train: 0.9000 loss_val: 0.3805 acc_val: 0.9000 auc_val: 0.8400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2001s\n",
      "12\n",
      "loss_train: 1.0137 acc_train: 0.6000 loss_val: 1.0105 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2211s\n",
      "13\n",
      "loss_train: 0.0003 acc_train: 1.0000 loss_val: 0.0004 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2291s\n",
      "14\n",
      "loss_train: 0.0004 acc_train: 1.0000 loss_val: 0.0004 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2366s\n",
      "15\n",
      "loss_train: 0.0004 acc_train: 1.0000 loss_val: 0.0004 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2433s\n",
      "16\n",
      "loss_train: 0.0004 acc_train: 1.0000 loss_val: 0.0005 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2492s\n",
      "17\n",
      "loss_train: 0.0005 acc_train: 1.0000 loss_val: 0.0005 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2547s\n",
      "18\n",
      "loss_train: 0.0005 acc_train: 1.0000 loss_val: 0.0006 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2614s\n",
      "19\n",
      "loss_train: 0.0006 acc_train: 1.0000 loss_val: 0.0006 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2687s\n",
      "20\n",
      "loss_train: 0.0006 acc_train: 1.0000 loss_val: 0.0007 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2757s\n",
      "21\n",
      "loss_train: 0.0007 acc_train: 1.0000 loss_val: 0.0007 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2827s\n",
      "22\n",
      "loss_train: 0.0007 acc_train: 1.0000 loss_val: 0.0008 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2892s\n",
      "23\n",
      "loss_train: 0.0008 acc_train: 1.0000 loss_val: 0.0009 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2962s\n",
      "24\n",
      "loss_train: 0.0009 acc_train: 1.0000 loss_val: 0.0009 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3042s\n",
      "25\n",
      "loss_train: 0.0009 acc_train: 1.0000 loss_val: 0.0010 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3092s\n",
      "26\n",
      "loss_train: 0.0011 acc_train: 1.0000 loss_val: 0.0012 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3152s\n",
      "27\n",
      "loss_train: 0.0011 acc_train: 1.0000 loss_val: 0.0012 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3202s\n",
      "28\n",
      "loss_train: 0.0012 acc_train: 1.0000 loss_val: 0.0013 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3265s\n",
      "29\n",
      "loss_train: 0.0013 acc_train: 1.0000 loss_val: 0.0014 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3320s\n",
      "30\n",
      "loss_train: 0.0014 acc_train: 1.0000 loss_val: 0.0015 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3380s\n",
      "31\n",
      "loss_train: 0.0015 acc_train: 1.0000 loss_val: 0.0016 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3460s\n",
      "32\n",
      "loss_train: 0.0017 acc_train: 1.0000 loss_val: 0.0018 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3525s\n",
      "33\n",
      "loss_train: 0.0017 acc_train: 1.0000 loss_val: 0.0019 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3585s\n",
      "34\n",
      "loss_train: 0.0019 acc_train: 1.0000 loss_val: 0.0020 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3635s\n",
      "35\n",
      "loss_train: 0.0020 acc_train: 1.0000 loss_val: 0.0021 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3703s\n",
      "36\n",
      "loss_train: 0.3189 acc_train: 0.9000 loss_val: 0.3196 acc_val: 0.9000 auc_val: 0.6533 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3908s\n",
      "37\n",
      "loss_train: 0.4243 acc_train: 0.9000 loss_val: 0.4310 acc_val: 0.9000 auc_val: 0.7111 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4105s\n",
      "38\n",
      "loss_train: 0.4077 acc_train: 0.9000 loss_val: 0.4121 acc_val: 0.9000 auc_val: 0.7333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4324s\n",
      "Test set results: loss= 0.4121 accuracy= 0.9000 auc_test: 0.7333 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3769 acc_train: 0.9000 loss_val: 0.3463 acc_val: 0.9000 auc_val: 0.5822 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0150s\n",
      "1\n",
      "loss_train: 0.3491 acc_train: 0.9000 loss_val: 0.3497 acc_val: 0.9000 auc_val: 0.5422 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0334s\n",
      "2\n",
      "loss_train: 0.3205 acc_train: 0.9000 loss_val: 0.3199 acc_val: 0.9000 auc_val: 0.6800 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0492s\n",
      "3\n",
      "loss_train: 0.3423 acc_train: 0.9000 loss_val: 0.3421 acc_val: 0.9000 auc_val: 0.5556 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0674s\n",
      "4\n",
      "loss_train: 0.2939 acc_train: 0.9000 loss_val: 0.2931 acc_val: 0.9000 auc_val: 0.7956 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0831s\n",
      "5\n",
      "loss_train: 0.3496 acc_train: 0.9000 loss_val: 0.3489 acc_val: 0.9000 auc_val: 0.5733 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1009s\n",
      "6\n",
      "loss_train: 0.3050 acc_train: 0.9000 loss_val: 0.3042 acc_val: 0.9000 auc_val: 0.7600 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1159s\n",
      "7\n",
      "loss_train: 0.3264 acc_train: 0.9000 loss_val: 0.3261 acc_val: 0.9000 auc_val: 0.5867 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1329s\n",
      "8\n",
      "loss_train: 0.2744 acc_train: 0.9000 loss_val: 0.2741 acc_val: 0.9000 auc_val: 0.7778 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1520s\n",
      "9\n",
      "loss_train: 0.2499 acc_train: 0.9000 loss_val: 0.2495 acc_val: 0.9000 auc_val: 0.8711 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1707s\n",
      "10\n",
      "loss_train: 0.2851 acc_train: 0.9000 loss_val: 0.2846 acc_val: 0.9000 auc_val: 0.7689 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1903s\n",
      "11\n",
      "loss_train: 0.2630 acc_train: 0.9000 loss_val: 0.2624 acc_val: 0.9000 auc_val: 0.8267 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2094s\n",
      "12\n",
      "loss_train: 0.9857 acc_train: 0.6000 loss_val: 0.9860 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2196s\n",
      "13\n",
      "loss_train: 0.0021 acc_train: 1.0000 loss_val: 0.0022 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2259s\n",
      "14\n",
      "loss_train: 0.0022 acc_train: 1.0000 loss_val: 0.0022 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2327s\n",
      "15\n",
      "loss_train: 0.0022 acc_train: 1.0000 loss_val: 0.0022 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2382s\n",
      "16\n",
      "loss_train: 0.0023 acc_train: 1.0000 loss_val: 0.0023 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2443s\n",
      "17\n",
      "loss_train: 0.0024 acc_train: 1.0000 loss_val: 0.0024 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2498s\n",
      "18\n",
      "loss_train: 0.0023 acc_train: 1.0000 loss_val: 0.0024 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2558s\n",
      "19\n",
      "loss_train: 0.0024 acc_train: 1.0000 loss_val: 0.0025 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2618s\n",
      "20\n",
      "loss_train: 0.0026 acc_train: 1.0000 loss_val: 0.0026 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2678s\n",
      "21\n",
      "loss_train: 0.0026 acc_train: 1.0000 loss_val: 0.0026 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2738s\n",
      "22\n",
      "loss_train: 0.0026 acc_train: 1.0000 loss_val: 0.0027 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2798s\n",
      "23\n",
      "loss_train: 0.0028 acc_train: 1.0000 loss_val: 0.0029 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2858s\n",
      "24\n",
      "loss_train: 0.0028 acc_train: 1.0000 loss_val: 0.0029 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2908s\n",
      "25\n",
      "loss_train: 0.0029 acc_train: 1.0000 loss_val: 0.0030 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2968s\n",
      "26\n",
      "loss_train: 0.0031 acc_train: 1.0000 loss_val: 0.0031 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3033s\n",
      "27\n",
      "loss_train: 0.0030 acc_train: 1.0000 loss_val: 0.0031 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3103s\n",
      "28\n",
      "loss_train: 0.0031 acc_train: 1.0000 loss_val: 0.0032 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3176s\n",
      "29\n",
      "loss_train: 0.0032 acc_train: 1.0000 loss_val: 0.0033 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3226s\n",
      "30\n",
      "loss_train: 0.0033 acc_train: 1.0000 loss_val: 0.0033 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3289s\n",
      "31\n",
      "loss_train: 0.0034 acc_train: 1.0000 loss_val: 0.0034 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3362s\n",
      "32\n",
      "loss_train: 0.0035 acc_train: 1.0000 loss_val: 0.0036 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3432s\n",
      "33\n",
      "loss_train: 0.0035 acc_train: 1.0000 loss_val: 0.0035 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3495s\n",
      "34\n",
      "loss_train: 0.0035 acc_train: 1.0000 loss_val: 0.0036 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3550s\n",
      "35\n",
      "loss_train: 0.0036 acc_train: 1.0000 loss_val: 0.0036 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3600s\n",
      "36\n",
      "loss_train: 0.3214 acc_train: 0.9000 loss_val: 0.3217 acc_val: 0.9000 auc_val: 0.6756 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3788s\n",
      "37\n",
      "loss_train: 0.4439 acc_train: 0.9000 loss_val: 0.4440 acc_val: 0.9000 auc_val: 0.7422 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3958s\n",
      "38\n",
      "loss_train: 0.4209 acc_train: 0.9000 loss_val: 0.4190 acc_val: 0.9000 auc_val: 0.7333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4126s\n",
      "Test set results: loss= 0.4190 accuracy= 0.9000 auc_test: 0.7333 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3735 acc_train: 0.9000 loss_val: 0.3381 acc_val: 0.9000 auc_val: 0.5467 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0188s\n",
      "1\n",
      "loss_train: 0.3519 acc_train: 0.9000 loss_val: 0.3517 acc_val: 0.9000 auc_val: 0.5244 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0353s\n",
      "2\n",
      "loss_train: 0.3121 acc_train: 0.9000 loss_val: 0.3120 acc_val: 0.9000 auc_val: 0.6800 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0523s\n",
      "3\n",
      "loss_train: 0.3360 acc_train: 0.9000 loss_val: 0.3357 acc_val: 0.9000 auc_val: 0.5689 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0703s\n",
      "4\n",
      "loss_train: 0.2885 acc_train: 0.9000 loss_val: 0.2884 acc_val: 0.9000 auc_val: 0.8178 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0883s\n",
      "5\n",
      "loss_train: 0.3371 acc_train: 0.9000 loss_val: 0.3370 acc_val: 0.9000 auc_val: 0.6044 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1037s\n",
      "6\n",
      "loss_train: 0.2911 acc_train: 0.9000 loss_val: 0.2909 acc_val: 0.9000 auc_val: 0.7867 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1192s\n",
      "7\n",
      "loss_train: 0.3161 acc_train: 0.9000 loss_val: 0.3160 acc_val: 0.9000 auc_val: 0.6311 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1383s\n",
      "8\n",
      "loss_train: 0.2713 acc_train: 0.9000 loss_val: 0.2712 acc_val: 0.9000 auc_val: 0.7911 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1550s\n",
      "9\n",
      "loss_train: 0.2505 acc_train: 0.9000 loss_val: 0.2505 acc_val: 0.9000 auc_val: 0.9067 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1706s\n",
      "10\n",
      "loss_train: 0.2768 acc_train: 0.9000 loss_val: 0.2767 acc_val: 0.9000 auc_val: 0.7956 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1856s\n",
      "11\n",
      "loss_train: 0.2637 acc_train: 0.9000 loss_val: 0.2637 acc_val: 0.9000 auc_val: 0.8444 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2022s\n",
      "12\n",
      "loss_train: 1.0040 acc_train: 0.6000 loss_val: 1.0047 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2102s\n",
      "13\n",
      "loss_train: 0.0026 acc_train: 1.0000 loss_val: 0.0026 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2162s\n",
      "14\n",
      "loss_train: 0.0026 acc_train: 1.0000 loss_val: 0.0026 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2222s\n",
      "15\n",
      "loss_train: 0.0026 acc_train: 1.0000 loss_val: 0.0027 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2322s\n",
      "16\n",
      "loss_train: 0.0027 acc_train: 1.0000 loss_val: 0.0027 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2402s\n",
      "17\n",
      "loss_train: 0.0028 acc_train: 1.0000 loss_val: 0.0029 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2480s\n",
      "18\n",
      "loss_train: 0.0028 acc_train: 1.0000 loss_val: 0.0028 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2530s\n",
      "19\n",
      "loss_train: 0.0029 acc_train: 1.0000 loss_val: 0.0029 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2607s\n",
      "20\n",
      "loss_train: 0.0030 acc_train: 1.0000 loss_val: 0.0031 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2667s\n",
      "21\n",
      "loss_train: 0.0030 acc_train: 1.0000 loss_val: 0.0031 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2730s\n",
      "22\n",
      "loss_train: 0.0031 acc_train: 1.0000 loss_val: 0.0032 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2790s\n",
      "23\n",
      "loss_train: 0.0033 acc_train: 1.0000 loss_val: 0.0034 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2850s\n",
      "24\n",
      "loss_train: 0.0033 acc_train: 1.0000 loss_val: 0.0034 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2910s\n",
      "25\n",
      "loss_train: 0.0034 acc_train: 1.0000 loss_val: 0.0035 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2970s\n",
      "26\n",
      "loss_train: 0.0036 acc_train: 1.0000 loss_val: 0.0037 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3036s\n",
      "27\n",
      "loss_train: 0.0036 acc_train: 1.0000 loss_val: 0.0037 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3103s\n",
      "28\n",
      "loss_train: 0.0037 acc_train: 1.0000 loss_val: 0.0038 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3163s\n",
      "29\n",
      "loss_train: 0.0038 acc_train: 1.0000 loss_val: 0.0039 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3223s\n",
      "30\n",
      "loss_train: 0.0039 acc_train: 1.0000 loss_val: 0.0040 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3288s\n",
      "31\n",
      "loss_train: 0.0040 acc_train: 1.0000 loss_val: 0.0041 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3348s\n",
      "32\n",
      "loss_train: 0.0042 acc_train: 1.0000 loss_val: 0.0042 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3408s\n",
      "33\n",
      "loss_train: 0.0041 acc_train: 1.0000 loss_val: 0.0042 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3468s\n",
      "34\n",
      "loss_train: 0.0042 acc_train: 1.0000 loss_val: 0.0042 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3538s\n",
      "35\n",
      "loss_train: 0.0042 acc_train: 1.0000 loss_val: 0.0043 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3618s\n",
      "36\n",
      "loss_train: 0.3066 acc_train: 0.9000 loss_val: 0.3064 acc_val: 0.9000 auc_val: 0.6667 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3820s\n",
      "37\n",
      "loss_train: 0.3762 acc_train: 0.9000 loss_val: 0.3755 acc_val: 0.9000 auc_val: 0.7467 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4020s\n",
      "38\n",
      "loss_train: 0.3596 acc_train: 0.9000 loss_val: 0.3574 acc_val: 0.9000 auc_val: 0.6978 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4216s\n",
      "Test set results: loss= 0.3574 accuracy= 0.9000 auc_test: 0.6978 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3693 acc_train: 0.9000 loss_val: 0.3435 acc_val: 0.9000 auc_val: 0.5244 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0152s\n",
      "1\n",
      "loss_train: 0.3415 acc_train: 0.9000 loss_val: 0.3412 acc_val: 0.9000 auc_val: 0.5467 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0361s\n",
      "2\n",
      "loss_train: 0.3054 acc_train: 0.9000 loss_val: 0.3053 acc_val: 0.9000 auc_val: 0.7022 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0534s\n",
      "3\n",
      "loss_train: 0.3241 acc_train: 0.9000 loss_val: 0.3238 acc_val: 0.9000 auc_val: 0.6178 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0729s\n",
      "4\n",
      "loss_train: 0.2955 acc_train: 0.9000 loss_val: 0.2956 acc_val: 0.9000 auc_val: 0.8222 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0919s\n",
      "5\n",
      "loss_train: 0.3283 acc_train: 0.9000 loss_val: 0.3281 acc_val: 0.9000 auc_val: 0.6400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1103s\n",
      "6\n",
      "loss_train: 0.2906 acc_train: 0.9000 loss_val: 0.2905 acc_val: 0.9000 auc_val: 0.8400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1289s\n",
      "7\n",
      "loss_train: 0.3123 acc_train: 0.9000 loss_val: 0.3122 acc_val: 0.9000 auc_val: 0.6622 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1479s\n",
      "8\n",
      "loss_train: 0.2766 acc_train: 0.9000 loss_val: 0.2765 acc_val: 0.9000 auc_val: 0.8089 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1669s\n",
      "9\n",
      "loss_train: 0.2653 acc_train: 0.9000 loss_val: 0.2653 acc_val: 0.9000 auc_val: 0.8978 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1864s\n",
      "10\n",
      "loss_train: 0.2772 acc_train: 0.9000 loss_val: 0.2770 acc_val: 0.9000 auc_val: 0.8222 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2025s\n",
      "11\n",
      "loss_train: 0.2767 acc_train: 0.9000 loss_val: 0.2763 acc_val: 0.9000 auc_val: 0.8533 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2190s\n",
      "12\n",
      "loss_train: 0.9895 acc_train: 0.6000 loss_val: 0.9908 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2300s\n",
      "13\n",
      "loss_train: 0.0034 acc_train: 1.0000 loss_val: 0.0034 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2392s\n",
      "14\n",
      "loss_train: 0.0034 acc_train: 1.0000 loss_val: 0.0034 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2472s\n",
      "15\n",
      "loss_train: 0.0035 acc_train: 1.0000 loss_val: 0.0035 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2552s\n",
      "16\n",
      "loss_train: 0.0035 acc_train: 1.0000 loss_val: 0.0036 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2632s\n",
      "17\n",
      "loss_train: 0.0037 acc_train: 1.0000 loss_val: 0.0038 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2692s\n",
      "18\n",
      "loss_train: 0.0037 acc_train: 1.0000 loss_val: 0.0038 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2762s\n",
      "19\n",
      "loss_train: 0.0038 acc_train: 1.0000 loss_val: 0.0039 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2823s\n",
      "20\n",
      "loss_train: 0.0040 acc_train: 1.0000 loss_val: 0.0041 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2883s\n",
      "21\n",
      "loss_train: 0.0041 acc_train: 1.0000 loss_val: 0.0042 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2953s\n",
      "22\n",
      "loss_train: 0.0042 acc_train: 1.0000 loss_val: 0.0043 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3009s\n",
      "23\n",
      "loss_train: 0.0045 acc_train: 1.0000 loss_val: 0.0047 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3069s\n",
      "24\n",
      "loss_train: 0.0045 acc_train: 1.0000 loss_val: 0.0046 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3141s\n",
      "25\n",
      "loss_train: 0.0047 acc_train: 1.0000 loss_val: 0.0049 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3221s\n",
      "26\n",
      "loss_train: 0.0049 acc_train: 1.0000 loss_val: 0.0051 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3302s\n",
      "27\n",
      "loss_train: 0.0050 acc_train: 1.0000 loss_val: 0.0052 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3385s\n",
      "28\n",
      "loss_train: 0.0051 acc_train: 1.0000 loss_val: 0.0052 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3468s\n",
      "29\n",
      "loss_train: 0.0053 acc_train: 1.0000 loss_val: 0.0054 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3548s\n",
      "30\n",
      "loss_train: 0.0053 acc_train: 1.0000 loss_val: 0.0054 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3626s\n",
      "31\n",
      "loss_train: 0.0055 acc_train: 1.0000 loss_val: 0.0056 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3706s\n",
      "32\n",
      "loss_train: 0.0057 acc_train: 1.0000 loss_val: 0.0057 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3786s\n",
      "33\n",
      "loss_train: 0.0057 acc_train: 1.0000 loss_val: 0.0057 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3866s\n",
      "34\n",
      "loss_train: 0.0056 acc_train: 1.0000 loss_val: 0.0056 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3936s\n",
      "35\n",
      "loss_train: 0.0057 acc_train: 1.0000 loss_val: 0.0057 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4022s\n",
      "36\n",
      "loss_train: 0.3076 acc_train: 0.9000 loss_val: 0.3083 acc_val: 0.9000 auc_val: 0.6578 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4192s\n",
      "37\n",
      "loss_train: 0.3892 acc_train: 0.9000 loss_val: 0.3917 acc_val: 0.9000 auc_val: 0.7511 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4405s\n",
      "38\n",
      "loss_train: 0.3717 acc_train: 0.9000 loss_val: 0.3718 acc_val: 0.9000 auc_val: 0.7022 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4583s\n",
      "Test set results: loss= 0.3718 accuracy= 0.9000 auc_test: 0.7022 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3591 acc_train: 0.9000 loss_val: 0.3348 acc_val: 0.9000 auc_val: 0.5378 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0140s\n",
      "1\n",
      "loss_train: 0.3458 acc_train: 0.9000 loss_val: 0.3461 acc_val: 0.9000 auc_val: 0.5244 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0300s\n",
      "2\n",
      "loss_train: 0.2948 acc_train: 0.9000 loss_val: 0.2947 acc_val: 0.9000 auc_val: 0.7378 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0485s\n",
      "3\n",
      "loss_train: 0.3216 acc_train: 0.9000 loss_val: 0.3215 acc_val: 0.9000 auc_val: 0.6089 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0675s\n",
      "4\n",
      "loss_train: 0.2873 acc_train: 0.9000 loss_val: 0.2871 acc_val: 0.9000 auc_val: 0.8089 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0835s\n",
      "5\n",
      "loss_train: 0.3157 acc_train: 0.9000 loss_val: 0.3155 acc_val: 0.9000 auc_val: 0.6400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1041s\n",
      "6\n",
      "loss_train: 0.2761 acc_train: 0.9000 loss_val: 0.2760 acc_val: 0.9000 auc_val: 0.8400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1231s\n",
      "7\n",
      "loss_train: 0.3044 acc_train: 0.9000 loss_val: 0.3043 acc_val: 0.9000 auc_val: 0.6889 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1437s\n",
      "8\n",
      "loss_train: 0.2697 acc_train: 0.9000 loss_val: 0.2695 acc_val: 0.9000 auc_val: 0.7956 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1648s\n",
      "9\n",
      "loss_train: 0.2617 acc_train: 0.9000 loss_val: 0.2618 acc_val: 0.9000 auc_val: 0.8756 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1852s\n",
      "10\n",
      "loss_train: 0.2716 acc_train: 0.9000 loss_val: 0.2716 acc_val: 0.9000 auc_val: 0.8311 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2005s\n",
      "11\n",
      "loss_train: 0.2682 acc_train: 0.9000 loss_val: 0.2681 acc_val: 0.9000 auc_val: 0.8356 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2197s\n",
      "12\n",
      "loss_train: 1.0040 acc_train: 0.6000 loss_val: 1.0051 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2277s\n",
      "13\n",
      "loss_train: 0.0041 acc_train: 1.0000 loss_val: 0.0041 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2342s\n",
      "14\n",
      "loss_train: 0.0041 acc_train: 1.0000 loss_val: 0.0041 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2425s\n",
      "15\n",
      "loss_train: 0.0042 acc_train: 1.0000 loss_val: 0.0043 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2505s\n",
      "16\n",
      "loss_train: 0.0042 acc_train: 1.0000 loss_val: 0.0043 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2585s\n",
      "17\n",
      "loss_train: 0.0045 acc_train: 1.0000 loss_val: 0.0046 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2665s\n",
      "18\n",
      "loss_train: 0.0044 acc_train: 1.0000 loss_val: 0.0046 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2745s\n",
      "19\n",
      "loss_train: 0.0047 acc_train: 1.0000 loss_val: 0.0049 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2825s\n",
      "20\n",
      "loss_train: 0.0049 acc_train: 1.0000 loss_val: 0.0051 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2896s\n",
      "21\n",
      "loss_train: 0.0050 acc_train: 1.0000 loss_val: 0.0053 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2959s\n",
      "22\n",
      "loss_train: 0.0051 acc_train: 1.0000 loss_val: 0.0054 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3025s\n",
      "23\n",
      "loss_train: 0.0056 acc_train: 1.0000 loss_val: 0.0058 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3085s\n",
      "24\n",
      "loss_train: 0.0056 acc_train: 1.0000 loss_val: 0.0058 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3155s\n",
      "25\n",
      "loss_train: 0.0059 acc_train: 1.0000 loss_val: 0.0061 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3219s\n",
      "26\n",
      "loss_train: 0.0061 acc_train: 1.0000 loss_val: 0.0063 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3282s\n",
      "27\n",
      "loss_train: 0.0063 acc_train: 1.0000 loss_val: 0.0065 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3347s\n",
      "28\n",
      "loss_train: 0.0064 acc_train: 1.0000 loss_val: 0.0066 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3407s\n",
      "29\n",
      "loss_train: 0.0067 acc_train: 1.0000 loss_val: 0.0069 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3484s\n",
      "30\n",
      "loss_train: 0.0067 acc_train: 1.0000 loss_val: 0.0068 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3554s\n",
      "31\n",
      "loss_train: 0.0070 acc_train: 1.0000 loss_val: 0.0071 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3634s\n",
      "32\n",
      "loss_train: 0.0071 acc_train: 1.0000 loss_val: 0.0071 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3704s\n",
      "33\n",
      "loss_train: 0.0071 acc_train: 1.0000 loss_val: 0.0071 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3787s\n",
      "34\n",
      "loss_train: 0.0070 acc_train: 1.0000 loss_val: 0.0069 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3907s\n",
      "35\n",
      "loss_train: 0.0071 acc_train: 1.0000 loss_val: 0.0070 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4057s\n",
      "36\n",
      "loss_train: 0.2991 acc_train: 0.9000 loss_val: 0.2988 acc_val: 0.9000 auc_val: 0.6800 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4302s\n",
      "37\n",
      "loss_train: 0.3549 acc_train: 0.9000 loss_val: 0.3540 acc_val: 0.9000 auc_val: 0.7600 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4524s\n",
      "38\n",
      "loss_train: 0.3326 acc_train: 0.9000 loss_val: 0.3305 acc_val: 0.9000 auc_val: 0.7111 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4718s\n",
      "Test set results: loss= 0.3305 accuracy= 0.9000 auc_test: 0.7111 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3515 acc_train: 0.9000 loss_val: 0.3403 acc_val: 0.9000 auc_val: 0.5200 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0181s\n",
      "1\n",
      "loss_train: 0.3378 acc_train: 0.9000 loss_val: 0.3375 acc_val: 0.9000 auc_val: 0.5422 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0395s\n",
      "2\n",
      "loss_train: 0.2901 acc_train: 0.9000 loss_val: 0.2900 acc_val: 0.9000 auc_val: 0.7200 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0551s\n",
      "3\n",
      "loss_train: 0.3098 acc_train: 0.9000 loss_val: 0.3094 acc_val: 0.9000 auc_val: 0.6489 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0720s\n",
      "4\n",
      "loss_train: 0.2898 acc_train: 0.9000 loss_val: 0.2897 acc_val: 0.9000 auc_val: 0.8267 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0906s\n",
      "5\n",
      "loss_train: 0.3082 acc_train: 0.9000 loss_val: 0.3080 acc_val: 0.9000 auc_val: 0.6844 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1083s\n",
      "6\n",
      "loss_train: 0.2785 acc_train: 0.9000 loss_val: 0.2785 acc_val: 0.9000 auc_val: 0.8578 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1303s\n",
      "7\n",
      "loss_train: 0.2994 acc_train: 0.9000 loss_val: 0.2993 acc_val: 0.9000 auc_val: 0.7333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1507s\n",
      "8\n",
      "loss_train: 0.2694 acc_train: 0.9000 loss_val: 0.2692 acc_val: 0.9000 auc_val: 0.8400 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1703s\n",
      "9\n",
      "loss_train: 0.2672 acc_train: 0.9000 loss_val: 0.2672 acc_val: 0.9000 auc_val: 0.8844 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1905s\n",
      "10\n",
      "loss_train: 0.2770 acc_train: 0.9000 loss_val: 0.2769 acc_val: 0.9000 auc_val: 0.8267 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2084s\n",
      "11\n",
      "loss_train: 0.2794 acc_train: 0.9000 loss_val: 0.2793 acc_val: 0.9000 auc_val: 0.8133 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2289s\n",
      "12\n",
      "loss_train: 0.9749 acc_train: 0.6000 loss_val: 0.9764 acc_val: 0.6000 auc_val: 0.7500 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2392s\n",
      "13\n",
      "loss_train: 0.0048 acc_train: 1.0000 loss_val: 0.0048 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2490s\n",
      "14\n",
      "loss_train: 0.0047 acc_train: 1.0000 loss_val: 0.0048 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2565s\n",
      "15\n",
      "loss_train: 0.0049 acc_train: 1.0000 loss_val: 0.0050 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2635s\n",
      "16\n",
      "loss_train: 0.0049 acc_train: 1.0000 loss_val: 0.0050 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2709s\n",
      "17\n",
      "loss_train: 0.0052 acc_train: 1.0000 loss_val: 0.0054 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2775s\n",
      "18\n",
      "loss_train: 0.0051 acc_train: 1.0000 loss_val: 0.0053 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2853s\n",
      "19\n",
      "loss_train: 0.0054 acc_train: 1.0000 loss_val: 0.0056 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2948s\n",
      "20\n",
      "loss_train: 0.0056 acc_train: 1.0000 loss_val: 0.0058 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3039s\n",
      "21\n",
      "loss_train: 0.0058 acc_train: 1.0000 loss_val: 0.0060 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3125s\n",
      "22\n",
      "loss_train: 0.0059 acc_train: 1.0000 loss_val: 0.0061 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3206s\n",
      "23\n",
      "loss_train: 0.0064 acc_train: 1.0000 loss_val: 0.0067 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3276s\n",
      "24\n",
      "loss_train: 0.0064 acc_train: 1.0000 loss_val: 0.0066 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3346s\n",
      "25\n",
      "loss_train: 0.0068 acc_train: 1.0000 loss_val: 0.0070 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3416s\n",
      "26\n",
      "loss_train: 0.0069 acc_train: 1.0000 loss_val: 0.0071 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3490s\n",
      "27\n",
      "loss_train: 0.0071 acc_train: 1.0000 loss_val: 0.0073 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3571s\n",
      "28\n",
      "loss_train: 0.0071 acc_train: 1.0000 loss_val: 0.0072 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3653s\n",
      "29\n",
      "loss_train: 0.0074 acc_train: 1.0000 loss_val: 0.0073 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3723s\n",
      "30\n",
      "loss_train: 0.0072 acc_train: 1.0000 loss_val: 0.0070 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3793s\n",
      "31\n",
      "loss_train: 0.0072 acc_train: 1.0000 loss_val: 0.0069 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3859s\n",
      "32\n",
      "loss_train: 0.0070 acc_train: 1.0000 loss_val: 0.0067 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3933s\n",
      "33\n",
      "loss_train: 0.0067 acc_train: 1.0000 loss_val: 0.0063 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3999s\n",
      "34\n",
      "loss_train: 0.0062 acc_train: 1.0000 loss_val: 0.0058 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4067s\n",
      "35\n",
      "loss_train: 0.0059 acc_train: 1.0000 loss_val: 0.0053 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4161s\n",
      "36\n",
      "loss_train: 0.2942 acc_train: 0.9000 loss_val: 0.2944 acc_val: 0.9000 auc_val: 0.6889 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4352s\n",
      "37\n",
      "loss_train: 0.3448 acc_train: 0.9000 loss_val: 0.3462 acc_val: 0.9000 auc_val: 0.7422 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4526s\n",
      "38\n",
      "loss_train: 0.3224 acc_train: 0.9000 loss_val: 0.3224 acc_val: 0.9000 auc_val: 0.6978 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4722s\n",
      "Test set results: loss= 0.3224 accuracy= 0.9000 auc_test: 0.6978 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3348 acc_train: 0.9000 loss_val: 0.3366 acc_val: 0.9000 auc_val: 0.5556 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0183s\n",
      "1\n",
      "loss_train: 0.3434 acc_train: 0.9000 loss_val: 0.3438 acc_val: 0.9000 auc_val: 0.5778 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0363s\n",
      "2\n",
      "loss_train: 0.2874 acc_train: 0.9000 loss_val: 0.2874 acc_val: 0.9000 auc_val: 0.7289 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0575s\n",
      "3\n",
      "loss_train: 0.3070 acc_train: 0.9000 loss_val: 0.3071 acc_val: 0.9000 auc_val: 0.6533 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0790s\n",
      "4\n",
      "loss_train: 0.2781 acc_train: 0.9000 loss_val: 0.2777 acc_val: 0.9000 auc_val: 0.8444 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0971s\n",
      "5\n",
      "loss_train: 0.2973 acc_train: 0.9000 loss_val: 0.2970 acc_val: 0.9000 auc_val: 0.7111 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1155s\n",
      "6\n",
      "loss_train: 0.2712 acc_train: 0.9000 loss_val: 0.2711 acc_val: 0.9000 auc_val: 0.8622 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1353s\n",
      "7\n",
      "loss_train: 0.2951 acc_train: 0.9000 loss_val: 0.2951 acc_val: 0.9000 auc_val: 0.7556 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1558s\n",
      "8\n",
      "loss_train: 0.2537 acc_train: 0.9000 loss_val: 0.2535 acc_val: 0.9000 auc_val: 0.8667 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1763s\n",
      "9\n",
      "loss_train: 0.2538 acc_train: 0.9000 loss_val: 0.2537 acc_val: 0.9000 auc_val: 0.9022 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1978s\n",
      "10\n",
      "loss_train: 0.2692 acc_train: 0.9000 loss_val: 0.2692 acc_val: 0.9000 auc_val: 0.8267 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2178s\n",
      "11\n",
      "loss_train: 0.2669 acc_train: 0.9000 loss_val: 0.2668 acc_val: 0.9000 auc_val: 0.8311 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2391s\n",
      "12\n",
      "loss_train: 1.0469 acc_train: 0.6000 loss_val: 1.0459 acc_val: 0.6000 auc_val: 0.8333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2497s\n",
      "13\n",
      "loss_train: 0.0013 acc_train: 1.0000 loss_val: 0.0014 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2597s\n",
      "14\n",
      "loss_train: 0.0014 acc_train: 1.0000 loss_val: 0.0015 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2681s\n",
      "15\n",
      "loss_train: 0.0015 acc_train: 1.0000 loss_val: 0.0017 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2755s\n",
      "16\n",
      "loss_train: 0.0018 acc_train: 1.0000 loss_val: 0.0020 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2828s\n",
      "17\n",
      "loss_train: 0.0021 acc_train: 1.0000 loss_val: 0.0025 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2897s\n",
      "18\n",
      "loss_train: 0.0024 acc_train: 1.0000 loss_val: 0.0028 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2965s\n",
      "19\n",
      "loss_train: 0.0029 acc_train: 1.0000 loss_val: 0.0035 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3045s\n",
      "20\n",
      "loss_train: 0.0035 acc_train: 1.0000 loss_val: 0.0041 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3135s\n",
      "21\n",
      "loss_train: 0.0041 acc_train: 1.0000 loss_val: 0.0047 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3227s\n",
      "22\n",
      "loss_train: 0.0046 acc_train: 1.0000 loss_val: 0.0051 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3318s\n",
      "23\n",
      "loss_train: 0.0053 acc_train: 1.0000 loss_val: 0.0056 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3403s\n",
      "24\n",
      "loss_train: 0.0053 acc_train: 1.0000 loss_val: 0.0055 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3493s\n",
      "25\n",
      "loss_train: 0.0057 acc_train: 1.0000 loss_val: 0.0059 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3583s\n",
      "26\n",
      "loss_train: 0.0059 acc_train: 1.0000 loss_val: 0.0061 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3676s\n",
      "27\n",
      "loss_train: 0.0061 acc_train: 1.0000 loss_val: 0.0063 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3746s\n",
      "28\n",
      "loss_train: 0.0061 acc_train: 1.0000 loss_val: 0.0063 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3825s\n",
      "29\n",
      "loss_train: 0.0065 acc_train: 1.0000 loss_val: 0.0066 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.3920s\n",
      "30\n",
      "loss_train: 0.0064 acc_train: 1.0000 loss_val: 0.0066 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4006s\n",
      "31\n",
      "loss_train: 0.0067 acc_train: 1.0000 loss_val: 0.0068 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4088s\n",
      "32\n",
      "loss_train: 0.0068 acc_train: 1.0000 loss_val: 0.0068 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4188s\n",
      "33\n",
      "loss_train: 0.0069 acc_train: 1.0000 loss_val: 0.0068 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4278s\n",
      "34\n",
      "loss_train: 0.0066 acc_train: 1.0000 loss_val: 0.0066 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4348s\n",
      "35\n",
      "loss_train: 0.0068 acc_train: 1.0000 loss_val: 0.0066 acc_val: 1.0000 auc_val: 0.0000 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4418s\n",
      "36\n",
      "loss_train: 0.2904 acc_train: 0.9000 loss_val: 0.2906 acc_val: 0.9000 auc_val: 0.7289 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4618s\n",
      "37\n",
      "loss_train: 0.2988 acc_train: 0.9000 loss_val: 0.2978 acc_val: 0.9000 auc_val: 0.7600 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.4815s\n",
      "38\n",
      "loss_train: 0.2925 acc_train: 0.9000 loss_val: 0.2924 acc_val: 0.9000 auc_val: 0.6933 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.5036s\n",
      "Test set results: loss= 0.2924 accuracy= 0.9000 auc_test: 0.6933 per_test: 0.0000 recall_test: 0.0000 f1_test: 0.0000\n",
      "0\n",
      "loss_train: 0.3449 acc_train: 0.9000 loss_val: 0.3453 acc_val: 0.9000 auc_val: 0.4711 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0175s\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m t_total \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[1;32m----> 7\u001B[0m     val \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 训练并获得结果\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# 检查是否返回了None值\u001B[39;00m\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWarning: train(epoch) returned None for epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Skipping this iteration.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[21], line 30\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epoch)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# print(output[:, 1])\u001B[39;00m\n\u001B[0;32m     28\u001B[0m acc_train \u001B[38;5;241m=\u001B[39m acc_measure(output, labels)\n\u001B[1;32m---> 30\u001B[0m \u001B[43mloss_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     33\u001B[0m train_model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\hypergraph\\lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\hypergraph\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\hypergraph\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "num_epochs = 1000\n",
    "early_stopping = 30\n",
    "val_watch = []\n",
    "t_total = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    val = train(epoch)  # 训练并获得结果\n",
    "    if val is None:  # 检查是否返回了None值\n",
    "        print(f\"Warning: train(epoch) returned None for epoch {epoch}. Skipping this iteration.\")\n",
    "        continue\n",
    "    \n",
    "    val_watch.append(val)  # 将结果添加到val_watch\n",
    "    test()\n",
    "    if epoch > early_stopping and val_watch[-1] > np.mean(val_watch[-(early_stopping + 1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "print(\"Printing the weights : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypergraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}