{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_data\n",
    "import numpy as np\n",
    "import models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_file = 'D:/zhuomian/file/弱网中鲁棒性的恶意节点检测/exp/dataset/20241106_testTX_constantUniform_simtime-100_num_nodes-50_BHradio-0_SFradio-0_fieldLength-20_uniform-1/ProcessedMonitorSnifferRx.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\zhuomian\\file\\弱网中鲁棒性的恶意节点检测\\exp\\utils.py:395: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:653.)\n",
      "  return torch.sparse.FloatTensor(indices, values, shape)\n"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(threshold=np.inf)  # 这将打印所有内容，去掉折叠\n",
    "processed_data, adj, T, group_num = load_data(1,data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[0, 0, 1, 1, 2, 2, 2, 3, 4],\n",
      "                       [0, 1, 0, 1, 2, 3, 4, 3, 4]]),\n",
      "       values=tensor([0.5000, 0.5000, 0.3333, 0.6667, 0.5000, 0.2500, 0.2500,\n",
      "                      1.0000, 1.0000]),\n",
      "       size=(5, 5), nnz=9, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 4],\n",
      "                       [0, 1, 0, 1, 2, 3, 4, 5, 4, 5]]),\n",
      "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      "       size=(5, 6), nnz=10, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "# 设置numpy的打印选项，显示更多行列\n",
    "\n",
    "\n",
    "# 打印节点特征（processed_data.x）\n",
    "# print(processed_data)\n",
    "print(adj[12])\n",
    "print(T[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印边连接关系（processed_data.edge_index）\n",
    "# print(processed_data[-1].edge_index.numpy().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5],\n",
      "        [0, 1, 1, 2, 2, 2]])\n",
      "tensor([1.0000, 0.5000, 0.0000])\n",
      "tensor([[  0.0000,   0.0000,   0.0000,   0.0000,   3.0000,   0.0000,   0.0000,\n",
      "           0.0000, 115.5520,  22.0000, -93.5521],\n",
      "        [ 51.0000,   0.0000,   0.0000,   0.0000,   3.0000,   8.0000,   0.0000,\n",
      "           0.0000, 115.4168,  22.0000, -93.4169],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "          50.0000, 115.5520,  22.0000, -93.5521],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "           1.0000,  16.9696, -68.2015, -85.1711],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "           1.0000,  25.3437, -68.2015, -93.5452],\n",
      "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
      "           1.0000,  16.9696, -68.2015, -85.1711]])\n"
     ]
    }
   ],
   "source": [
    "# 打印节点标签（processed_data.y）\n",
    "# print(processed_data[0].y.numpy())\n",
    "# print(processed_data[-1].x[:,0:8].numpy().size)\n",
    "# print(processed_data[0].y.numpy())\n",
    "print(processed_data[12].edge_index)\n",
    "print(processed_data[12].edge_weights)\n",
    "print(processed_data[12].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HypergraphModel(\n",
      "  (layer1): HypergraphConvLayer(\n",
      "    (conv): HypergraphConv(8, 32)\n",
      "  )\n",
      "  (layer2): HypergraphConvLayer(\n",
      "    (conv): HypergraphConv(64, 32)\n",
      "  )\n",
      "  (edge_conv): GraphConvolution()\n",
      "  (class_classifier): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=2, bias=True)\n",
      "  )\n",
      "  (norm1): CustomBatchNorm()\n",
      "  (norm2): CustomBatchNorm()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_model = models.HypergraphModel(8, 3)\n",
    "print(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "from utils import accuracy, auc, precision, recall, f1_score\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "criteria = torch.nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "weight_decay = 5e-4\n",
    "optimizer = optim.Adam(train_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "acc_measure = accuracy\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    train_model.train()\n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    # print(processed_data[0].x[0:8].shape)\n",
    "    # print(processed_data[0].edge_weights.shape)\n",
    "    # print(processed_data[0].edge_index.shape)\n",
    "    for i in range(group_num):\n",
    "        print(i)\n",
    "        output = train_model(processed_data[i].x[:, 0:8], processed_data[i].edge_index, \n",
    "                                 processed_data[i].edge_weights, processed_data[i].x[:, 8:11], adj[i], T[i])\n",
    "        # print(output)\n",
    "        labels = processed_data[i].y\n",
    "        loss_train = criteria(output, labels)\n",
    "        # print(output[:, 1])\n",
    "        acc_train = acc_measure(output, labels)\n",
    "        \n",
    "        loss_train.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_model.eval()\n",
    "        output = train_model(processed_data[i].x[:, 0:8], processed_data[i].edge_index, \n",
    "                                 processed_data[i].edge_weights, processed_data[i].x[:, 8:11], adj[i], T[i])\n",
    "        # print(output)\n",
    "        loss_val = criteria(output, labels)\n",
    "        acc_val = acc_measure(output, labels)\n",
    "        auc_val = auc(output, labels)\n",
    "        per_val = precision(output, labels)\n",
    "        recall_val = recall(output, labels)\n",
    "        f1_val = f1_score(output, labels)\n",
    "        print(\n",
    "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "            'auc_val: {:.4f}'.format(auc_val.item()),\n",
    "            'per_val: {:.4f}'.format(per_val),\n",
    "            'recall_val: {:.4f}'.format(recall_val),\n",
    "            'f1_val: {:.4f}'.format(f1_val),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "    return loss_val.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    train_model.eval()\n",
    "    output = train_model(processed_data[group_num-1].x[:, 0:8], processed_data[group_num-1].edge_index, \n",
    "                             processed_data[group_num-1].edge_weights, processed_data[group_num-1].x[:, 8:11], adj[group_num-1], T[group_num-1])\n",
    "    labels = processed_data[group_num-1].y\n",
    "    \n",
    "    loss_test = criteria(output, labels)\n",
    "    acc_test = acc_measure(output, labels)\n",
    "    auc_test = auc(output, labels)\n",
    "    per_test = precision(output, labels)\n",
    "    recall_test = recall(output, labels)\n",
    "    f1_test = f1_score(output, labels)\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()),\n",
    "         'auc_test: {:.4f}'.format(auc_test.item()),\n",
    "            'per_test: {:.4f}'.format(per_test),\n",
    "            'recall_test: {:.4f}'.format(recall_test),\n",
    "            'f1_test: {:.4f}'.format(f1_test))\n",
    "    return acc_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss_train: 0.5509 acc_train: 0.9000 loss_val: 0.9685 acc_val: 0.9000 auc_val: 0.4667 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0190s\n",
      "1\n",
      "loss_train: 1.2212 acc_train: 0.9000 loss_val: 0.6917 acc_val: 0.9000 auc_val: 0.3689 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0400s\n",
      "2\n",
      "loss_train: 0.6086 acc_train: 0.9000 loss_val: 0.4070 acc_val: 0.9000 auc_val: 0.6533 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.0577s\n",
      "3\n",
      "loss_train: 0.4888 acc_train: 0.8400 loss_val: 2.6455 acc_val: 0.1200 auc_val: 0.6267 per_val: 0.1020 recall_val: 1.0000 f1_val: 0.1852 time: 0.0752s\n",
      "4\n",
      "loss_train: 2.1113 acc_train: 0.1000 loss_val: 1.5428 acc_val: 0.1000 auc_val: 0.5067 per_val: 0.1000 recall_val: 1.0000 f1_val: 0.1818 time: 0.0927s\n",
      "5\n",
      "loss_train: 1.4831 acc_train: 0.2000 loss_val: 0.4822 acc_val: 0.8600 auc_val: 0.3511 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1087s\n",
      "6\n",
      "loss_train: 0.4733 acc_train: 0.9000 loss_val: 0.4003 acc_val: 0.9000 auc_val: 0.5467 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1242s\n",
      "7\n",
      "loss_train: 0.5104 acc_train: 0.9000 loss_val: 0.9686 acc_val: 0.9000 auc_val: 0.2489 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1382s\n",
      "8\n",
      "loss_train: 0.8645 acc_train: 0.9000 loss_val: 1.3161 acc_val: 0.9000 auc_val: 0.5156 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1532s\n",
      "9\n",
      "loss_train: 1.4631 acc_train: 0.9000 loss_val: 1.9808 acc_val: 0.9000 auc_val: 0.4222 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1677s\n",
      "10\n",
      "loss_train: 1.7878 acc_train: 0.9000 loss_val: 2.2454 acc_val: 0.9000 auc_val: 0.4889 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.1837s\n",
      "11\n",
      "loss_train: 2.0401 acc_train: 0.9000 loss_val: 2.4119 acc_val: 0.9000 auc_val: 0.5333 per_val: 0.0000 recall_val: 0.0000 f1_val: 0.0000 time: 0.2008s\n",
      "12\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5x5 and 3x32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m t_total \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[1;32m----> 7\u001B[0m     val \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 训练并获得结果\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m val \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# 检查是否返回了None值\u001B[39;00m\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWarning: train(epoch) returned None for epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Skipping this iteration.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[11], line 22\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epoch)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(group_num):\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(i)\n\u001B[1;32m---> 22\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocessed_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprocessed_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mprocessed_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprocessed_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m11\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madj\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mT\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;66;03m# print(output)\u001B[39;00m\n\u001B[0;32m     25\u001B[0m     labels \u001B[38;5;241m=\u001B[39m processed_data[i]\u001B[38;5;241m.\u001B[39my\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\hypergraph\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\hypergraph\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\zhuomian\\file\\弱网中鲁棒性的恶意节点检测\\exp\\models.py:38\u001B[0m, in \u001B[0;36mHypergraphModel.forward\u001B[1;34m(self, x, edge_index, edge_weight, edge_features, adj_e, T)\u001B[0m\n\u001B[0;32m     35\u001B[0m node_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate_node_features(x, edge_index)  \u001B[38;5;66;03m# 聚合超图卷积得到的节点特征\u001B[39;00m\n\u001B[0;32m     37\u001B[0m edge_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm2(edge_features)\n\u001B[1;32m---> 38\u001B[0m shared_feature \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnode_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madj_e\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 将边特征融合到节点特征中\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# 分类结果\u001B[39;00m\n\u001B[0;32m     41\u001B[0m class_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass_classifier(shared_feature)\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\hypergraph\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\hypergraph\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\zhuomian\\file\\弱网中鲁棒性的恶意节点检测\\exp\\layers.py:61\u001B[0m, in \u001B[0;36mGraphConvolution.forward\u001B[1;34m(self, H_v, edge_features, adj_v, T)\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;124;03mprint(\"adjusted_A is \", adjusted_A)\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;124;03mnormalized_adjusted_A = adjusted_A / adjusted_A.max(0, keepdim=True)[0]\u001B[39;00m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;124;03mprint(\"normalized adjusted A is \", normalized_adjusted_A)\u001B[39;00m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# to avoid missing feature's influence, we don't normalize the A\u001B[39;00m\n\u001B[1;32m---> 61\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43madjusted_A\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mH_v\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     63\u001B[0m     output \u001B[38;5;241m=\u001B[39m output \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (5x5 and 3x32)"
     ]
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(True)\n",
    "num_epochs = 1000\n",
    "early_stopping = 30\n",
    "val_watch = []\n",
    "t_total = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    val = train(epoch)  # 训练并获得结果\n",
    "    if val is None:  # 检查是否返回了None值\n",
    "        print(f\"Warning: train(epoch) returned None for epoch {epoch}. Skipping this iteration.\")\n",
    "        continue\n",
    "    \n",
    "    val_watch.append(val)  # 将结果添加到val_watch\n",
    "    test()\n",
    "    if epoch > early_stopping and val_watch[-1] > np.mean(val_watch[-(early_stopping + 1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "print(\"Printing the weights : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}